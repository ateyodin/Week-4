{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "#set paths\n",
    "normal_train = glob('data/chest_xray/train/NORMAL/*.jpeg')\n",
    "pneumonia_train = glob('data/chest_xray/train/PNEUMONIA/*.jpeg')\n",
    "\n",
    "input_directory = r\"data/chest_xray/\"\n",
    "output_directory = r\"data/chest_xray/\"\n",
    "\n",
    "training_dir = input_directory + r\"train\"\n",
    "validation_dir = input_directory + r\"val\"\n",
    "testing_dir = input_directory + r\"test\"\n",
    "output_directory = r\"data/chest_xray/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(directory_path, remove=False):\n",
    "    if remove and os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reset_subplot_params(nrows, ncols, dpi):\n",
    "    subplot_params = {}\n",
    "    subplot_params[\"nrows\"] = nrows\n",
    "    subplot_params[\"ncols\"] = ncols\n",
    "\n",
    "    subplot_params[\"figsize_col\"] = subplot_params[\"ncols\"]*2.5\n",
    "    subplot_params[\"figsize_row\"] = subplot_params[\"nrows\"]*2.5\n",
    "    subplot_params[\"dpi\"] = dpi\n",
    "    subplot_params[\"facecolor\"] = 'w'\n",
    "    subplot_params[\"edgecolor\"] = 'k'\n",
    "    subplot_params[\"subplot_kw\"] = {'xticks': [], 'yticks': []}\n",
    "    subplot_params[\"axes.titlesize\"] = 'small'\n",
    "    subplot_params[\"hspace\"] = 0.5\n",
    "    subplot_params[\"wspace\"] = 0.3\n",
    "    \n",
    "    return subplot_params\n",
    "\n",
    "def get_reset_plot_params(figsize=(15, 5), title=\"\", xlabel =\"\", ylabel=\"\", legends=[], title_fontsize = 18, label_fontsize = 14, image_file_name=\"\", save = False, dpi=100, update_image=True):\n",
    "    plot_params = {}\n",
    "    \n",
    "    plot_params[\"figsize\"] = figsize\n",
    "    \n",
    "    plot_params[\"title\"] = title\n",
    "    \n",
    "    plot_params[\"xlabel\"] = xlabel\n",
    "    plot_params[\"ylabel\"] = ylabel\n",
    "    \n",
    "    plot_params[\"legends\"] = legends \n",
    "    \n",
    "    plot_params[\"title_fontsize\"] = title_fontsize\n",
    "    plot_params[\"axes.titlesize\"] = \"small\"\n",
    "    plot_params[\"label_fontsize\"] = label_fontsize\n",
    "    \n",
    "    plot_params[\"image_file_name\"] = image_file_name\n",
    "    plot_params[\"save\"] = save\n",
    "    plot_params[\"update_image\"] = update_image\n",
    "    \n",
    "    plot_params[\"subplot\"] = None\n",
    "    return plot_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model_dir = output_directory + r\"models/\"\n",
    "main_log_dir = output_directory + r\"logs/\"\n",
    "\n",
    "#create directorys\n",
    "create_directory(output_directory, True)\n",
    "create_directory(main_model_dir, True)\n",
    "create_directory(main_log_dir, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "normal = np.random.choice(normal_train, 13)\n",
    "pneumonia = np.random.choice(pneumonia_train, 12)\n",
    "data = np.concatenate((normal, pneumonia))\n",
    "labels = 13 * ['Normal'] + 12 *['Pneumonia']\n",
    "\n",
    "N, R, C = 25, 5, 5\n",
    "plt.figure(figsize=(12, 9))\n",
    "for k, (src, label) in enumerate(zip(data, labels)):\n",
    "    im = Image.open(src).convert('RGB')\n",
    "    plt.subplot(R, C, k+1)\n",
    "    plt.title(label)\n",
    "    plt.imshow(np.asarray(im))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "\n",
    "CLASSES = 2\n",
    "    \n",
    "# setup model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "predictions = Dense(CLASSES, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "   \n",
    "# transfer learning\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "'''      \n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "WIDTH = 299\n",
    "HEIGHT = 299\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "rescale = 1./255\n",
    "\n",
    "# data prep\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=rescale,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=rescale)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "    \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=rescale)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    testing_dir,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "model_dir = main_model_dir + time.strftime('%Y-%m-%d %H-%M-%S') + \"/\"\n",
    "log_dir = main_log_dir + time.strftime('%Y-%m-%d %H-%M-%S')\n",
    "\n",
    "create_directory(model_dir, remove=True)\n",
    "create_directory(log_dir, remove=True)\n",
    "\n",
    "model_file = model_dir + \"{epoch:02d}-val_acc-{val_accuracy:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    model_file, \n",
    "    monitor='val_accuracy', \n",
    "    save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    update_freq = 'batch')\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    cooldown=2,\n",
    "    min_lr=0.0000000001,\n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "optimizer=optimizers.Adam()\n",
    "loss='categorical_crossentropy'\n",
    "metrics=['accuracy']\n",
    "epochs = 50\n",
    "\n",
    "#add optimizer\n",
    "model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "#train model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks, \n",
    "    verbose=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel = 'Epoch'\n",
    "legends = ['Training', 'Validation']\n",
    "\n",
    "ylim_pad = [0.01, 0.1]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot training & validation Accuracy values\n",
    "\n",
    "y1 = history.history['accuracy']\n",
    "y2 = history.history['val_accuracy']\n",
    "\n",
    "min_y = min(min(y1), min(y2))-ylim_pad[0]\n",
    "max_y = max(max(y1), max(y2))+ylim_pad[0]\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "\n",
    "plt.plot(y1)\n",
    "plt.plot(y2)\n",
    "\n",
    "plt.title('Model Accuracy', fontsize=17)\n",
    "plt.xlabel(xlabel, fontsize=15)\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.ylim(min_y, max_y)\n",
    "plt.legend(legends, loc='upper left')\n",
    "plt.grid()\n",
    "\n",
    "                         \n",
    "# Plot training & validation loss values\n",
    "    \n",
    "y1 = history.history['loss']\n",
    "y2 = history.history['val_loss']\n",
    "\n",
    "min_y = min(min(y1), min(y2))-ylim_pad[1]\n",
    "max_y = max(max(y1), max(y2))+ylim_pad[1]    \n",
    "    \n",
    "plt.subplot(122)\n",
    "\n",
    "plt.plot(y1)\n",
    "plt.plot(y2)\n",
    "\n",
    "plt.title('Model Loss', fontsize=17)\n",
    "plt.xlabel(xlabel, fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.ylim(min_y, max_y)\n",
    "plt.legend(legends, loc='upper left')\n",
    "plt.grid()\n",
    "                         \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the best model\n",
    "from keras.models import load_model\n",
    "\n",
    "cur_dir =model_dir\n",
    "model_names = os.listdir(cur_dir)\n",
    "for i in range(len(model_names)):\n",
    "    print(i, model_names[i])\n",
    "    \n",
    "last_checkpoint = model_names[len(model_names)-1]\n",
    "model = load_model(model_dir + last_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate model\n",
    "print(\"Evaluate\")\n",
    "result  = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "\n",
    "print(\"%s%.2f  \"% (\"Loss     : \", result[0]))\n",
    "print(\"%s%.2f%s\"% (\"Accuracy : \", result[1]*100, \"%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "print(\"results\")\n",
    "y_pred = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)  \n",
    "y_pred = y_pred.argmax(axis=-1)\n",
    "y_true=test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation model with metrics (confusion matrix, recall, precision, f1...)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "classes = os.listdir(training_dir)\n",
    "\n",
    "figure_directory = \"data/chest_xray/output/figures\"\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)\n",
    "    \n",
    "image_file_name_CM = figure_directory+\"/CM\"\n",
    "\n",
    "title = model_file.split(\"/\")\n",
    "model_title = \"/\".join([i for i in title[3:]])\n",
    "\n",
    "precision = precision_score(y_true, y_pred) \n",
    "recall = recall_score(y_true, y_pred) \n",
    "f1 = f1_score(y_true, y_pred) \n",
    "\n",
    "print(\"-\"*90)\n",
    "print(\"Derived Report\")\n",
    "print(\"-\"*90)\n",
    "print(\"%s%.2f%s\"% (\"Precision     : \", precision*100, \"%\"))\n",
    "print(\"%s%.2f%s\"% (\"Recall        : \", recall*100,    \"%\"))\n",
    "print(\"%s%.2f%s\"% (\"F1-Score      : \", f1*100,        \"%\"))\n",
    "print(\"-\"*90)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(10,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.yticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.title(\"Confusion Matrix for Model File (Test Dataset): \\n\"+model_title, fontsize=11)\n",
    "fig.savefig(image_file_name_CM, dpi=100)\n",
    "plt.show()    \n",
    "\n",
    "cls_report_print = classification_report(y_true, y_pred, target_names=classes)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"-\"*90)\n",
    "print(\"Report for Model File: \", model_title)\n",
    "print(\"-\"*90)\n",
    "print(cls_report_print)\n",
    "print(\"-\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "numofbatch = len(test_generator)\n",
    "\n",
    "batch_no = random.randint(0, numofbatch-1)\n",
    "\n",
    "y_img_batch, y_true_batch = test_generator[batch_no] \n",
    "y_true_batch = y_true_batch.argmax(axis=-1)\n",
    "\n",
    "y_pred_batch = model.predict(y_img_batch)\n",
    "y_pred_batch = y_pred_batch.argmax(axis=-1)\n",
    "\n",
    "\n",
    "sizeofbatch = len(y_true_batch)\n",
    "print(\"-\"*35)\n",
    "print(\"%s%d\"%     (\"Selected Batch No       : \", batch_no))\n",
    "print(\"-\"*35)\n",
    "print(\"%s%d\"%     (\"Batch Size              : \", len(y_pred_batch)))\n",
    "print(\"-\"*35)\n",
    "print(\"%s%.2f%s\"% (\"Accuracy                : \", np.mean(y_true==y_pred)*100, \"%\"))\n",
    "print(\"-\"*35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "def show_predictions(y_img_batch, y_true, y_pred, subplot_params, plot_params, class_map, testing_dir, image_file_name, count=8, sample=True):\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=subplot_params[\"nrows\"], ncols=subplot_params[\"ncols\"], \n",
    "        figsize=(subplot_params[\"figsize_col\"], subplot_params[\"figsize_row\"]),\n",
    "        dpi=subplot_params[\"dpi\"], facecolor=subplot_params[\"facecolor\"], \n",
    "        edgecolor=subplot_params[\"edgecolor\"], subplot_kw=subplot_params[\"subplot_kw\"])\n",
    "    plt.rcParams.update({'axes.titlesize': plot_params[\"axes.titlesize\"]})\n",
    "    plt.subplots_adjust(hspace=subplot_params[\"hspace\"], wspace=subplot_params[\"wspace\"])\n",
    "    \n",
    "    file_names = test_generator.filenames\n",
    "    m = {}\n",
    "    length = len(y_true)\n",
    "    for i in range(0, count): \n",
    "        num = i\n",
    "        if sample:\n",
    "            num = random.randint(0, length-1)\n",
    "            while num in m:\n",
    "                num = int(random.randint(0, length-1))\n",
    "\n",
    "            m[num]=1\n",
    "\n",
    "\n",
    "        plt.subplot(subplot_params[\"nrows\"], subplot_params[\"ncols\"], i+1)\n",
    "        img = cv2.imread(testing_dir+\"\\\\\"+ file_names[num], 1)\n",
    "        plt.imshow(img)\n",
    "\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        \n",
    "        original = class_map[y_true[num]]\n",
    "        predicted = class_map[y_pred[num]]\n",
    "        \n",
    "        \n",
    "        title_text = (\"%s%s%s%s%s\"%(\"True: \", original, \"\\n\", \"Pred: \", predicted))\n",
    "        \n",
    "        if original==predicted:\n",
    "            plt.title(title_text)\n",
    "        else:\n",
    "            plt.title(title_text, color='red')\n",
    "            \n",
    "\n",
    "        if plot_params[\"update_image\"] and os.path.exists(image_file_name):\n",
    "            os.remove(image_file_name)   \n",
    "\n",
    "        fig.savefig(image_file_name, dpi=subplot_params[\"dpi\"])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_name_batch = figure_directory+\"/result\"\n",
    "image_file_name_sample = figure_directory+\"/sample\"\n",
    "\n",
    "batch_size_t = len(y_true_batch)\n",
    "\n",
    "class_map = {v: k for k, v in test_generator.class_indices.items()}\n",
    "\n",
    "dpi=100\n",
    "\n",
    "ncols = 5\n",
    "nrows = 2\n",
    "\n",
    "count = ncols*nrows\n",
    "\n",
    "subplot_params = get_reset_subplot_params(nrows, ncols, dpi)\n",
    "plot_params = get_reset_plot_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show images with true value and prediction value\n",
    "show_predictions(y_img_batch, y_true_batch, y_pred_batch, subplot_params, plot_params, class_map, testing_dir, image_file_name_batch, count=count, sample=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
